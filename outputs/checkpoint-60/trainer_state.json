{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 60.0,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "grad_norm": 0.9649613499641418,
      "learning_rate": 4e-05,
      "loss": 6.7189,
      "step": 1
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.9649134278297424,
      "learning_rate": 8e-05,
      "loss": 6.7189,
      "step": 2
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.9635502696037292,
      "learning_rate": 0.00012,
      "loss": 6.6904,
      "step": 3
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.9834460616111755,
      "learning_rate": 0.00016,
      "loss": 6.522,
      "step": 4
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.0214017629623413,
      "learning_rate": 0.0002,
      "loss": 6.1268,
      "step": 5
    },
    {
      "epoch": 6.0,
      "grad_norm": 1.1650272607803345,
      "learning_rate": 0.00019636363636363636,
      "loss": 5.588,
      "step": 6
    },
    {
      "epoch": 7.0,
      "grad_norm": 1.3539499044418335,
      "learning_rate": 0.00019272727272727274,
      "loss": 4.9664,
      "step": 7
    },
    {
      "epoch": 8.0,
      "grad_norm": 1.6207696199417114,
      "learning_rate": 0.0001890909090909091,
      "loss": 4.3769,
      "step": 8
    },
    {
      "epoch": 9.0,
      "grad_norm": 1.8810290098190308,
      "learning_rate": 0.00018545454545454545,
      "loss": 3.7866,
      "step": 9
    },
    {
      "epoch": 10.0,
      "grad_norm": 5.302502155303955,
      "learning_rate": 0.00018181818181818183,
      "loss": 3.2309,
      "step": 10
    },
    {
      "epoch": 11.0,
      "grad_norm": 2.5833699703216553,
      "learning_rate": 0.0001781818181818182,
      "loss": 2.6997,
      "step": 11
    },
    {
      "epoch": 12.0,
      "grad_norm": 3.0092475414276123,
      "learning_rate": 0.00017454545454545454,
      "loss": 2.2036,
      "step": 12
    },
    {
      "epoch": 13.0,
      "grad_norm": 3.401439905166626,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.7256,
      "step": 13
    },
    {
      "epoch": 14.0,
      "grad_norm": 2.8202900886535645,
      "learning_rate": 0.00016727272727272728,
      "loss": 1.2693,
      "step": 14
    },
    {
      "epoch": 15.0,
      "grad_norm": 2.608217716217041,
      "learning_rate": 0.00016363636363636366,
      "loss": 0.8598,
      "step": 15
    },
    {
      "epoch": 16.0,
      "grad_norm": 2.4269003868103027,
      "learning_rate": 0.00016,
      "loss": 0.5352,
      "step": 16
    },
    {
      "epoch": 17.0,
      "grad_norm": 2.3710527420043945,
      "learning_rate": 0.00015636363636363637,
      "loss": 0.3013,
      "step": 17
    },
    {
      "epoch": 18.0,
      "grad_norm": 1.8512855768203735,
      "learning_rate": 0.00015272727272727275,
      "loss": 0.1752,
      "step": 18
    },
    {
      "epoch": 19.0,
      "grad_norm": 1.0427935123443604,
      "learning_rate": 0.0001490909090909091,
      "loss": 0.0967,
      "step": 19
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.5293823480606079,
      "learning_rate": 0.00014545454545454546,
      "loss": 0.0552,
      "step": 20
    },
    {
      "epoch": 21.0,
      "grad_norm": 1.4577022790908813,
      "learning_rate": 0.00014181818181818184,
      "loss": 0.0435,
      "step": 21
    },
    {
      "epoch": 22.0,
      "grad_norm": 3.175727367401123,
      "learning_rate": 0.0001381818181818182,
      "loss": 0.0403,
      "step": 22
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.6467217206954956,
      "learning_rate": 0.00013454545454545455,
      "loss": 0.0259,
      "step": 23
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.9610926508903503,
      "learning_rate": 0.00013090909090909093,
      "loss": 0.0194,
      "step": 24
    },
    {
      "epoch": 25.0,
      "grad_norm": 3.8593714237213135,
      "learning_rate": 0.00012727272727272728,
      "loss": 0.0276,
      "step": 25
    },
    {
      "epoch": 26.0,
      "grad_norm": 1.5180246829986572,
      "learning_rate": 0.00012363636363636364,
      "loss": 0.0286,
      "step": 26
    },
    {
      "epoch": 27.0,
      "grad_norm": 1.5181427001953125,
      "learning_rate": 0.00012,
      "loss": 0.0275,
      "step": 27
    },
    {
      "epoch": 28.0,
      "grad_norm": 1.1598315238952637,
      "learning_rate": 0.00011636363636363636,
      "loss": 0.0187,
      "step": 28
    },
    {
      "epoch": 29.0,
      "grad_norm": 2.681824207305908,
      "learning_rate": 0.00011272727272727272,
      "loss": 0.0211,
      "step": 29
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.4225660562515259,
      "learning_rate": 0.00010909090909090909,
      "loss": 0.0106,
      "step": 30
    },
    {
      "epoch": 31.0,
      "grad_norm": 1.1346406936645508,
      "learning_rate": 0.00010545454545454545,
      "loss": 0.0098,
      "step": 31
    },
    {
      "epoch": 32.0,
      "grad_norm": 2.79430890083313,
      "learning_rate": 0.00010181818181818181,
      "loss": 0.0127,
      "step": 32
    },
    {
      "epoch": 33.0,
      "grad_norm": 1.0244656801223755,
      "learning_rate": 9.818181818181818e-05,
      "loss": 0.0084,
      "step": 33
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.9447566270828247,
      "learning_rate": 9.454545454545455e-05,
      "loss": 0.0063,
      "step": 34
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.07874786853790283,
      "learning_rate": 9.090909090909092e-05,
      "loss": 0.0046,
      "step": 35
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.13887546956539154,
      "learning_rate": 8.727272727272727e-05,
      "loss": 0.0046,
      "step": 36
    },
    {
      "epoch": 37.0,
      "grad_norm": 4.872730255126953,
      "learning_rate": 8.363636363636364e-05,
      "loss": 0.0101,
      "step": 37
    },
    {
      "epoch": 38.0,
      "grad_norm": 1.0827733278274536,
      "learning_rate": 8e-05,
      "loss": 0.0062,
      "step": 38
    },
    {
      "epoch": 39.0,
      "grad_norm": 0.03947800397872925,
      "learning_rate": 7.636363636363637e-05,
      "loss": 0.0033,
      "step": 39
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.03985433280467987,
      "learning_rate": 7.272727272727273e-05,
      "loss": 0.0043,
      "step": 40
    },
    {
      "epoch": 41.0,
      "grad_norm": 0.2148490697145462,
      "learning_rate": 6.90909090909091e-05,
      "loss": 0.0052,
      "step": 41
    },
    {
      "epoch": 42.0,
      "grad_norm": 0.04423961043357849,
      "learning_rate": 6.545454545454546e-05,
      "loss": 0.0037,
      "step": 42
    },
    {
      "epoch": 43.0,
      "grad_norm": 0.08696506917476654,
      "learning_rate": 6.181818181818182e-05,
      "loss": 0.0042,
      "step": 43
    },
    {
      "epoch": 44.0,
      "grad_norm": 0.031107721850275993,
      "learning_rate": 5.818181818181818e-05,
      "loss": 0.0042,
      "step": 44
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.03992052376270294,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 0.004,
      "step": 45
    },
    {
      "epoch": 46.0,
      "grad_norm": 0.04974251240491867,
      "learning_rate": 5.090909090909091e-05,
      "loss": 0.004,
      "step": 46
    },
    {
      "epoch": 47.0,
      "grad_norm": 0.030293071642518044,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 0.004,
      "step": 47
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.02348134107887745,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 0.0037,
      "step": 48
    },
    {
      "epoch": 49.0,
      "grad_norm": 0.01867407187819481,
      "learning_rate": 4e-05,
      "loss": 0.0038,
      "step": 49
    },
    {
      "epoch": 50.0,
      "grad_norm": 0.015259252861142159,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 0.0044,
      "step": 50
    },
    {
      "epoch": 51.0,
      "grad_norm": 0.011581925675272942,
      "learning_rate": 3.272727272727273e-05,
      "loss": 0.0036,
      "step": 51
    },
    {
      "epoch": 52.0,
      "grad_norm": 0.009881556034088135,
      "learning_rate": 2.909090909090909e-05,
      "loss": 0.0039,
      "step": 52
    },
    {
      "epoch": 53.0,
      "grad_norm": 0.009863109327852726,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 0.0032,
      "step": 53
    },
    {
      "epoch": 54.0,
      "grad_norm": 0.007874853909015656,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 0.0038,
      "step": 54
    },
    {
      "epoch": 55.0,
      "grad_norm": 0.008971632458269596,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.0045,
      "step": 55
    },
    {
      "epoch": 56.0,
      "grad_norm": 0.009945960715413094,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 0.0033,
      "step": 56
    },
    {
      "epoch": 57.0,
      "grad_norm": 0.009155540727078915,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.0036,
      "step": 57
    },
    {
      "epoch": 58.0,
      "grad_norm": 0.008289420045912266,
      "learning_rate": 7.272727272727272e-06,
      "loss": 0.0043,
      "step": 58
    },
    {
      "epoch": 59.0,
      "grad_norm": 0.00943963322788477,
      "learning_rate": 3.636363636363636e-06,
      "loss": 0.0042,
      "step": 59
    },
    {
      "epoch": 60.0,
      "grad_norm": 0.009570425376296043,
      "learning_rate": 0.0,
      "loss": 0.0041,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 60,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4.941675252154368e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
